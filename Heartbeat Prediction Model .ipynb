{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sannjana Thinderu U16484810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEARTBEAT PREDICTION MODEL USING MACHINE LEARNING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heartbeat_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0     0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1     1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2     1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3     1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4     1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "...     ...    ...    ...     ...     ...     ...     ...     ...     ...   \n",
       "7955  0.929  0.871  0.805  0.7430  0.6510  0.5360  0.3940  0.2510  0.1400   \n",
       "7956  0.803  0.692  0.587  0.4470  0.3180  0.1900  0.1180  0.0777  0.1120   \n",
       "7957  1.000  0.967  0.620  0.3470  0.1390  0.0890  0.1040  0.1010  0.1070   \n",
       "7958  0.984  0.567  0.607  0.5830  0.6070  0.5750  0.5750  0.4880  0.3930   \n",
       "7959  0.974  0.913  0.866  0.8230  0.7460  0.6420  0.5480  0.4260  0.3250   \n",
       "\n",
       "         T10  ...     T72     T73     T74     T75    T76     T77     T78  \\\n",
       "0     0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010   \n",
       "1     0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070   \n",
       "2     0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770   \n",
       "3     0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210   \n",
       "4     0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519   \n",
       "...      ...  ...     ...     ...     ...     ...    ...     ...     ...   \n",
       "7955  0.1020  ...  0.4670  0.4670  0.4690  0.4700  0.469  0.4680  0.4680   \n",
       "7956  0.1520  ...  0.5620  0.5670  0.5610  0.5700  0.561  0.5650  0.5620   \n",
       "7957  0.1010  ...  0.1390  0.1510  0.1360  0.1510  0.139  0.1510  0.1420   \n",
       "7958  0.2380  ...  0.2220  0.2260  0.2260  0.2500  0.230  0.2420  0.2180   \n",
       "7959  0.2800  ...  0.3700  0.3860  0.3760  0.3800  0.382  0.3840  0.3750   \n",
       "\n",
       "        T79     T80  Target  \n",
       "0     0.205  0.2080       0  \n",
       "1     0.207  0.1720       0  \n",
       "2     0.452  0.0519       0  \n",
       "3     0.451  0.8690       0  \n",
       "4     0.082  0.0628       0  \n",
       "...     ...     ...     ...  \n",
       "7955  0.463  0.4710       4  \n",
       "7956  0.570  0.5610       4  \n",
       "7957  0.169  0.1630       4  \n",
       "7958  0.238  0.2180       4  \n",
       "7959  0.382  0.3800       4  \n",
       "\n",
       "[7960 rows x 81 columns]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T1        0\n",
       "T2        0\n",
       "T3        0\n",
       "T4        0\n",
       "T5        0\n",
       "         ..\n",
       "T77       0\n",
       "T78       0\n",
       "T79       0\n",
       "T80       0\n",
       "Target    0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data in 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sklearn library seperate the train and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating  the target variable \n",
    "train_target = train_set[['Target']]\n",
    "test_target = test_set[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test inputs\n",
    "train_inputs = train_set.drop(['Target'], axis=1)\n",
    "test_inputs = test_set.drop(['Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T71</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.06370</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.00637</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.00955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>0.77200</td>\n",
       "      <td>0.6710</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.57100</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>0.57500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>0.80500</td>\n",
       "      <td>0.7060</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.4710</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.01220</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>0.53600</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.5430</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.52500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.16400</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.28400</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.27700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.02740</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.13200</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.5020</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0.00893</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.4820</td>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.75900</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.74100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>0.70600</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.09480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807</th>\n",
       "      <td>0.66600</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>0.4730</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.38200</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.33700</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.3280</td>\n",
       "      <td>0.3280</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.32500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7544</th>\n",
       "      <td>0.71200</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.50700</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.5040</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.50400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.31200</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.29000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           T1      T2     T3      T4      T5      T6      T7       T8      T9  \\\n",
       "4390  1.00000  0.8540  0.497  0.2200  0.1720  0.1180  0.1050  0.06370  0.0669   \n",
       "7929  0.77200  0.6710  0.545  0.3920  0.2190  0.1130  0.0299  0.00000  0.0183   \n",
       "7771  0.80500  0.7060  0.603  0.4710  0.3300  0.1790  0.0835  0.01220  0.0000   \n",
       "4811  0.92500  0.7400  0.188  0.0000  0.0548  0.1230  0.1200  0.16400  0.2020   \n",
       "3700  1.00000  0.9130  0.370  0.0731  0.0411  0.0731  0.0274  0.02740  0.0137   \n",
       "...       ...     ...    ...     ...     ...     ...     ...      ...     ...   \n",
       "1782  0.00893  0.0714  0.235  0.3690  0.4820  0.5540  0.6900  0.75900  0.7860   \n",
       "6043  0.70600  0.6750  0.393  0.1210  0.0000  0.0806  0.1560  0.17100  0.1850   \n",
       "7807  0.66600  0.4970  0.482  0.4670  0.4730  0.4440  0.4320  0.38200  0.3400   \n",
       "7544  0.71200  0.5960  0.475  0.3420  0.2040  0.0953  0.0339  0.00485  0.0355   \n",
       "3865  1.00000  0.8610  0.327  0.0000  0.1490  0.2480  0.2500  0.27700  0.2970   \n",
       "\n",
       "         T10  ...     T71      T72     T73     T74     T75     T76     T77  \\\n",
       "4390  0.0382  ...  0.0318  0.00637  0.0287  0.0127  0.0223  0.0127  0.0255   \n",
       "7929  0.0748  ...  0.5680  0.57100  0.5730  0.5850  0.5800  0.5830  0.5710   \n",
       "7771  0.0209  ...  0.5410  0.53600  0.5440  0.5360  0.5430  0.5320  0.5410   \n",
       "4811  0.1680  ...  0.2880  0.28400  0.2770  0.2640  0.2740  0.2950  0.2980   \n",
       "3700  0.0183  ...  0.0594  0.13200  0.2880  0.5020  0.7530  0.9500  0.8490   \n",
       "...      ...  ...     ...      ...     ...     ...     ...     ...     ...   \n",
       "1782  0.7710  ...  0.7470  0.75000  0.7440  0.7380  0.7470  0.7320  0.7500   \n",
       "6043  0.1660  ...  0.1350  0.13300  0.1400  0.1180  0.1370  0.1280  0.1370   \n",
       "7807  0.2720  ...  0.3580  0.33700  0.3490  0.3340  0.3430  0.3280  0.3280   \n",
       "7544  0.0824  ...  0.5150  0.50700  0.5120  0.5060  0.5090  0.5010  0.5040   \n",
       "3865  0.2900  ...  0.3170  0.31200  0.3170  0.3140  0.2990  0.2990  0.3050   \n",
       "\n",
       "        T78     T79      T80  \n",
       "4390  0.000  0.0223  0.00955  \n",
       "7929  0.581  0.5730  0.57500  \n",
       "7771  0.527  0.5290  0.52500  \n",
       "4811  0.274  0.2670  0.27700  \n",
       "3700  0.461  0.1370  0.11000  \n",
       "...     ...     ...      ...  \n",
       "1782  0.735  0.7380  0.74100  \n",
       "6043  0.107  0.1230  0.09480  \n",
       "7807  0.328  0.3250  0.32500  \n",
       "7544  0.501  0.5070  0.50400  \n",
       "3865  0.305  0.2970  0.29000  \n",
       "\n",
       "[5572 rows x 80 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1',\n",
       " 'T2',\n",
       " 'T3',\n",
       " 'T4',\n",
       " 'T5',\n",
       " 'T6',\n",
       " 'T7',\n",
       " 'T8',\n",
       " 'T9',\n",
       " 'T10',\n",
       " 'T11',\n",
       " 'T12',\n",
       " 'T13',\n",
       " 'T14',\n",
       " 'T15',\n",
       " 'T16',\n",
       " 'T17',\n",
       " 'T18',\n",
       " 'T19',\n",
       " 'T20',\n",
       " 'T21',\n",
       " 'T22',\n",
       " 'T23',\n",
       " 'T24',\n",
       " 'T25',\n",
       " 'T26',\n",
       " 'T27',\n",
       " 'T28',\n",
       " 'T29',\n",
       " 'T30',\n",
       " 'T31',\n",
       " 'T32',\n",
       " 'T33',\n",
       " 'T34',\n",
       " 'T35',\n",
       " 'T36',\n",
       " 'T37',\n",
       " 'T38',\n",
       " 'T39',\n",
       " 'T40',\n",
       " 'T41',\n",
       " 'T42',\n",
       " 'T43',\n",
       " 'T44',\n",
       " 'T45',\n",
       " 'T46',\n",
       " 'T47',\n",
       " 'T48',\n",
       " 'T49',\n",
       " 'T50',\n",
       " 'T51',\n",
       " 'T52',\n",
       " 'T53',\n",
       " 'T54',\n",
       " 'T55',\n",
       " 'T56',\n",
       " 'T57',\n",
       " 'T58',\n",
       " 'T59',\n",
       " 'T60',\n",
       " 'T61',\n",
       " 'T62',\n",
       " 'T63',\n",
       " 'T64',\n",
       " 'T65',\n",
       " 'T66',\n",
       " 'T67',\n",
       " 'T68',\n",
       " 'T69',\n",
       " 'T70',\n",
       " 'T71',\n",
       " 'T72',\n",
       " 'T73',\n",
       " 'T74',\n",
       " 'T75',\n",
       " 'T76',\n",
       " 'T77',\n",
       " 'T78',\n",
       " 'T79',\n",
       " 'T80']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 80)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388, 80)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_x = np.array(train_inputs)\n",
    "test_x = np.array(test_inputs)\n",
    "\n",
    "train_y = np.array(train_target)\n",
    "test_y = np.array(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.     , 0.854  , 0.497  , 0.22   , 0.172  , 0.118  , 0.105  ,\n",
       "        0.0637 , 0.0669 , 0.0382 , 0.0637 , 0.035  , 0.051  , 0.0414 ,\n",
       "        0.0637 , 0.0446 , 0.0669 , 0.0573 , 0.0732 , 0.0669 , 0.0796 ,\n",
       "        0.0764 , 0.118  , 0.124  , 0.153  , 0.153  , 0.194  , 0.201  ,\n",
       "        0.242  , 0.252  , 0.287  , 0.283  , 0.315  , 0.287  , 0.274  ,\n",
       "        0.223  , 0.185  , 0.134  , 0.111  , 0.0732 , 0.0669 , 0.0382 ,\n",
       "        0.0446 , 0.0318 , 0.0318 , 0.0159 , 0.0287 , 0.0159 , 0.0318 ,\n",
       "        0.0127 , 0.0287 , 0.00637, 0.0255 , 0.0159 , 0.035  , 0.0191 ,\n",
       "        0.0446 , 0.0159 , 0.035  , 0.0255 , 0.0414 , 0.0287 , 0.0382 ,\n",
       "        0.0191 , 0.0318 , 0.0191 , 0.0255 , 0.0191 , 0.035  , 0.0159 ,\n",
       "        0.0318 , 0.00637, 0.0287 , 0.0127 , 0.0223 , 0.0127 , 0.0255 ,\n",
       "        0.     , 0.0223 , 0.00955],\n",
       "       [0.772  , 0.671  , 0.545  , 0.392  , 0.219  , 0.113  , 0.0299 ,\n",
       "        0.     , 0.0183 , 0.0748 , 0.183  , 0.319  , 0.367  , 0.447  ,\n",
       "        0.515  , 0.578  , 0.63   , 0.658  , 0.673  , 0.678  , 0.689  ,\n",
       "        0.693  , 0.709  , 0.721  , 0.733  , 0.743  , 0.759  , 0.781  ,\n",
       "        0.801  , 0.824  , 0.842  , 0.864  , 0.879  , 0.902  , 0.912  ,\n",
       "        0.932  , 0.939  , 0.939  , 0.93   , 0.917  , 0.882  , 0.844  ,\n",
       "        0.802  , 0.767  , 0.719  , 0.684  , 0.654  , 0.641  , 0.618  ,\n",
       "        0.61   , 0.605  , 0.606  , 0.603  , 0.6    , 0.596  , 0.598  ,\n",
       "        0.598  , 0.601  , 0.601  , 0.603  , 0.598  , 0.591  , 0.585  ,\n",
       "        0.585  , 0.578  , 0.583  , 0.581  , 0.576  , 0.575  , 0.571  ,\n",
       "        0.568  , 0.571  , 0.573  , 0.585  , 0.58   , 0.583  , 0.571  ,\n",
       "        0.581  , 0.573  , 0.575  ],\n",
       "       [0.805  , 0.706  , 0.603  , 0.471  , 0.33   , 0.179  , 0.0835 ,\n",
       "        0.0122 , 0.     , 0.0209 , 0.0817 , 0.19   , 0.315  , 0.35   ,\n",
       "        0.409  , 0.478  , 0.569  , 0.612  , 0.654  , 0.661  , 0.675  ,\n",
       "        0.671  , 0.689  , 0.69   , 0.703  , 0.708  , 0.727  , 0.73   ,\n",
       "        0.748  , 0.744  , 0.767  , 0.772  , 0.802  , 0.81   , 0.833  ,\n",
       "        0.849  , 0.87   , 0.877  , 0.899  , 0.906  , 0.922  , 0.91   ,\n",
       "        0.897  , 0.873  , 0.849  , 0.805  , 0.774  , 0.729  , 0.697  ,\n",
       "        0.659  , 0.64   , 0.603  , 0.598  , 0.576  , 0.584  , 0.579  ,\n",
       "        0.577  , 0.57   , 0.576  , 0.567  , 0.572  , 0.557  , 0.563  ,\n",
       "        0.56   , 0.565  , 0.541  , 0.548  , 0.536  , 0.55   , 0.543  ,\n",
       "        0.541  , 0.536  , 0.544  , 0.536  , 0.543  , 0.532  , 0.541  ,\n",
       "        0.527  , 0.529  , 0.525  ],\n",
       "       [0.925  , 0.74   , 0.188  , 0.     , 0.0548 , 0.123  , 0.12   ,\n",
       "        0.164  , 0.202  , 0.168  , 0.188  , 0.233  , 0.271  , 0.288  ,\n",
       "        0.284  , 0.305  , 0.305  , 0.298  , 0.301  , 0.308  , 0.298  ,\n",
       "        0.288  , 0.315  , 0.342  , 0.332  , 0.322  , 0.353  , 0.38   ,\n",
       "        0.408  , 0.401  , 0.432  , 0.473  , 0.479  , 0.514  , 0.517  ,\n",
       "        0.517  , 0.5    , 0.473  , 0.445  , 0.425  , 0.39   , 0.339  ,\n",
       "        0.325  , 0.312  , 0.298  , 0.288  , 0.284  , 0.288  , 0.274  ,\n",
       "        0.26   , 0.271  , 0.298  , 0.277  , 0.25   , 0.274  , 0.274  ,\n",
       "        0.281  , 0.291  , 0.291  , 0.284  , 0.281  , 0.26   , 0.281  ,\n",
       "        0.301  , 0.281  , 0.264  , 0.277  , 0.281  , 0.267  , 0.277  ,\n",
       "        0.288  , 0.284  , 0.277  , 0.264  , 0.274  , 0.295  , 0.298  ,\n",
       "        0.274  , 0.267  , 0.277  ],\n",
       "       [1.     , 0.913  , 0.37   , 0.0731 , 0.0411 , 0.0731 , 0.0274 ,\n",
       "        0.0274 , 0.0137 , 0.0183 , 0.0137 , 0.0137 , 0.00913, 0.0274 ,\n",
       "        0.0183 , 0.0411 , 0.0228 , 0.0457 , 0.032  , 0.032  , 0.0228 ,\n",
       "        0.0411 , 0.032  , 0.0502 , 0.0457 , 0.0548 , 0.032  , 0.0594 ,\n",
       "        0.0639 , 0.0913 , 0.0868 , 0.119  , 0.105  , 0.11   , 0.0776 ,\n",
       "        0.0868 , 0.0411 , 0.0548 , 0.032  , 0.0457 , 0.0274 , 0.0365 ,\n",
       "        0.0183 , 0.0365 , 0.0365 , 0.0411 , 0.0365 , 0.0548 , 0.0365 ,\n",
       "        0.0594 , 0.0594 , 0.0639 , 0.0685 , 0.0685 , 0.0548 , 0.0731 ,\n",
       "        0.0548 , 0.0685 , 0.0548 , 0.0639 , 0.0594 , 0.0548 , 0.0411 ,\n",
       "        0.0502 , 0.0274 , 0.032  , 0.00457, 0.032  , 0.00913, 0.0411 ,\n",
       "        0.0594 , 0.132  , 0.288  , 0.502  , 0.753  , 0.95   , 0.849  ,\n",
       "        0.461  , 0.137  , 0.11   ],\n",
       "       [1.     , 0.831  , 0.588  , 0.381  , 0.232  , 0.13   , 0.0593 ,\n",
       "        0.0226 , 0.     , 0.00565, 0.0113 , 0.0141 , 0.0169 , 0.0254 ,\n",
       "        0.0169 , 0.0254 , 0.0311 , 0.0254 , 0.0282 , 0.0226 , 0.0198 ,\n",
       "        0.0141 , 0.0339 , 0.0311 , 0.048  , 0.0678 , 0.0819 , 0.0932 ,\n",
       "        0.116  , 0.136  , 0.161  , 0.192  , 0.209  , 0.203  , 0.195  ,\n",
       "        0.175  , 0.175  , 0.167  , 0.161  , 0.158  , 0.15   , 0.15   ,\n",
       "        0.141  , 0.153  , 0.136  , 0.141  , 0.147  , 0.141  , 0.141  ,\n",
       "        0.141  , 0.147  , 0.136  , 0.141  , 0.144  , 0.144  , 0.136  ,\n",
       "        0.141  , 0.141  , 0.141  , 0.144  , 0.144  , 0.15   , 0.15   ,\n",
       "        0.153  , 0.184  , 0.201  , 0.192  , 0.24   , 0.254  , 0.274  ,\n",
       "        0.257  , 0.254  , 0.215  , 0.127  , 0.124  , 0.124  , 0.124  ,\n",
       "        0.133  , 0.133  , 0.138  ],\n",
       "       [1.     , 0.951  , 0.646  , 0.418  , 0.205  , 0.107  , 0.104  ,\n",
       "        0.118  , 0.153  , 0.17   , 0.159  , 0.138  , 0.127  , 0.124  ,\n",
       "        0.118  , 0.112  , 0.127  , 0.11   , 0.115  , 0.0922 , 0.072  ,\n",
       "        0.0519 , 0.0778 , 0.0951 , 0.0548 , 0.0749 , 0.0778 , 0.0403 ,\n",
       "        0.0663 , 0.0231 , 0.0115 , 0.0403 , 0.0634 , 0.0173 , 0.0375 ,\n",
       "        0.0548 , 0.0663 , 0.0576 , 0.0865 , 0.0893 , 0.104  , 0.118  ,\n",
       "        0.141  , 0.133  , 0.147  , 0.153  , 0.193  , 0.159  , 0.159  ,\n",
       "        0.156  , 0.144  , 0.153  , 0.156  , 0.167  , 0.153  , 0.156  ,\n",
       "        0.17   , 0.133  , 0.133  , 0.135  , 0.144  , 0.118  , 0.144  ,\n",
       "        0.13   , 0.147  , 0.11   , 0.13   , 0.133  , 0.13   , 0.124  ,\n",
       "        0.133  , 0.135  , 0.135  , 0.121  , 0.124  , 0.118  , 0.124  ,\n",
       "        0.133  , 0.101  , 0.115  ],\n",
       "       [0.966  , 0.845  , 0.507  , 0.199  , 0.108  , 0.0845 , 0.0777 ,\n",
       "        0.0541 , 0.0507 , 0.0439 , 0.0405 , 0.0473 , 0.0439 , 0.0405 ,\n",
       "        0.0473 , 0.0372 , 0.027  , 0.00338, 0.     , 0.     , 0.00676,\n",
       "        0.00338, 0.0101 , 0.     , 0.0135 , 0.027  , 0.0507 , 0.0608 ,\n",
       "        0.105  , 0.108  , 0.115  , 0.115  , 0.128  , 0.118  , 0.108  ,\n",
       "        0.111  , 0.122  , 0.115  , 0.111  , 0.105  , 0.101  , 0.105  ,\n",
       "        0.122  , 0.122  , 0.128  , 0.128  , 0.128  , 0.135  , 0.155  ,\n",
       "        0.149  , 0.149  , 0.142  , 0.135  , 0.135  , 0.122  , 0.111  ,\n",
       "        0.111  , 0.108  , 0.115  , 0.122  , 0.135  , 0.139  , 0.139  ,\n",
       "        0.149  , 0.152  , 0.162  , 0.162  , 0.159  , 0.162  , 0.142  ,\n",
       "        0.145  , 0.145  , 0.139  , 0.132  , 0.128  , 0.118  , 0.125  ,\n",
       "        0.135  , 0.145  , 0.139  ],\n",
       "       [0.981  , 0.877  , 0.47   , 0.144  , 0.0558 , 0.0581 , 0.0349 ,\n",
       "        0.0233 , 0.0302 , 0.0326 , 0.0395 , 0.0558 , 0.0674 , 0.0535 ,\n",
       "        0.0605 , 0.0628 , 0.0721 , 0.0698 , 0.0628 , 0.0651 , 0.0721 ,\n",
       "        0.0698 , 0.0674 , 0.0628 , 0.0721 , 0.0721 , 0.0744 , 0.0791 ,\n",
       "        0.086  , 0.0674 , 0.0512 , 0.0465 , 0.0372 , 0.0326 , 0.0349 ,\n",
       "        0.0488 , 0.0581 , 0.0558 , 0.0651 , 0.0767 , 0.0953 , 0.093  ,\n",
       "        0.093  , 0.0953 , 0.102  , 0.0953 , 0.0977 , 0.0953 , 0.1    ,\n",
       "        0.0884 , 0.0907 , 0.0907 , 0.093  , 0.0884 , 0.086  , 0.0767 ,\n",
       "        0.0651 , 0.0488 , 0.0442 , 0.0326 , 0.0326 , 0.0349 , 0.0419 ,\n",
       "        0.0558 , 0.0698 , 0.0767 , 0.086  , 0.114  , 0.119  , 0.121  ,\n",
       "        0.121  , 0.137  , 0.144  , 0.17   , 0.219  , 0.379  , 0.6    ,\n",
       "        0.842  , 1.     , 0.858  ],\n",
       "       [0.89   , 0.519  , 0.527  , 0.574  , 0.54   , 0.523  , 0.506  ,\n",
       "        0.511  , 0.38   , 0.262  , 0.0802 , 0.169  , 0.114  , 0.0591 ,\n",
       "        0.0675 , 0.0844 , 0.0591 , 0.0802 , 0.0295 , 0.0549 , 0.0675 ,\n",
       "        0.0717 , 0.0633 , 0.0886 , 0.0717 , 0.0759 , 0.0802 , 0.0886 ,\n",
       "        0.0675 , 0.105  , 0.101  , 0.11   , 0.105  , 0.143  , 0.165  ,\n",
       "        0.198  , 0.203  , 0.241  , 0.245  , 0.274  , 0.266  , 0.283  ,\n",
       "        0.291  , 0.278  , 0.253  , 0.287  , 0.253  , 0.236  , 0.232  ,\n",
       "        0.253  , 0.211  , 0.249  , 0.232  , 0.228  , 0.224  , 0.228  ,\n",
       "        0.169  , 0.219  , 0.207  , 0.194  , 0.194  , 0.224  , 0.181  ,\n",
       "        0.19   , 0.186  , 0.194  , 0.181  , 0.194  , 0.165  , 0.169  ,\n",
       "        0.16   , 0.181  , 0.139  , 0.165  , 0.156  , 0.181  , 0.165  ,\n",
       "        0.165  , 0.169  , 0.181  ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_x[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.     , 0.854  , 0.497  , ..., 0.     , 0.0223 , 0.00955],\n",
       "       [0.772  , 0.671  , 0.545  , ..., 0.581  , 0.573  , 0.575  ],\n",
       "       [0.805  , 0.706  , 0.603  , ..., 0.527  , 0.529  , 0.525  ],\n",
       "       ...,\n",
       "       [0.666  , 0.497  , 0.482  , ..., 0.328  , 0.325  , 0.325  ],\n",
       "       [0.712  , 0.596  , 0.475  , ..., 0.501  , 0.507  , 0.504  ],\n",
       "       [1.     , 0.861  , 0.327  , ..., 0.305  , 0.297  , 0.29   ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (2388, 80, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.     ],\n",
       "        [0.854  ],\n",
       "        [0.497  ],\n",
       "        ...,\n",
       "        [0.     ],\n",
       "        [0.0223 ],\n",
       "        [0.00955]],\n",
       "\n",
       "       [[0.772  ],\n",
       "        [0.671  ],\n",
       "        [0.545  ],\n",
       "        ...,\n",
       "        [0.581  ],\n",
       "        [0.573  ],\n",
       "        [0.575  ]],\n",
       "\n",
       "       [[0.805  ],\n",
       "        [0.706  ],\n",
       "        [0.603  ],\n",
       "        ...,\n",
       "        [0.527  ],\n",
       "        [0.529  ],\n",
       "        [0.525  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.666  ],\n",
       "        [0.497  ],\n",
       "        [0.482  ],\n",
       "        ...,\n",
       "        [0.328  ],\n",
       "        [0.325  ],\n",
       "        [0.325  ]],\n",
       "\n",
       "       [[0.712  ],\n",
       "        [0.596  ],\n",
       "        [0.475  ],\n",
       "        ...,\n",
       "        [0.501  ],\n",
       "        [0.507  ],\n",
       "        [0.504  ]],\n",
       "\n",
       "       [[1.     ],\n",
       "        [0.861  ],\n",
       "        [0.327  ],\n",
       "        ...,\n",
       "        [0.305  ],\n",
       "        [0.297  ],\n",
       "        [0.29   ]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [4]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.5791457286432161\n"
     ]
    }
   ],
   "source": [
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_y, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.5887772194304858\n"
     ]
    }
   ],
   "source": [
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_y, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input shape of our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 80, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is your input shape?\n",
    "#(meaning: how many neurons should be in the input layer?)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Cross-sectional Neural Network model using Keras with only one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=80))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 2s 11ms/step - loss: 0.8260 - accuracy: 0.7173 - val_loss: 0.6325 - val_accuracy: 0.7982\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.5819 - accuracy: 0.8004 - val_loss: 0.5608 - val_accuracy: 0.8141\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.8374 - val_loss: 0.4719 - val_accuracy: 0.8430\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8584 - val_loss: 0.4034 - val_accuracy: 0.8911\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8787 - val_loss: 0.3877 - val_accuracy: 0.8899\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8812 - val_loss: 0.3656 - val_accuracy: 0.8945\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8882 - val_loss: 0.3712 - val_accuracy: 0.9054\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8887 - val_loss: 0.3563 - val_accuracy: 0.8949\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8972 - val_loss: 0.3307 - val_accuracy: 0.9045\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8963 - val_loss: 0.3122 - val_accuracy: 0.9125\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3169 - accuracy: 0.9036 - val_loss: 0.3112 - val_accuracy: 0.9121\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3046 - accuracy: 0.9072 - val_loss: 0.3125 - val_accuracy: 0.9167\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.9058 - val_loss: 0.2973 - val_accuracy: 0.9196\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2921 - accuracy: 0.9104 - val_loss: 0.2875 - val_accuracy: 0.9146\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2994 - accuracy: 0.9051 - val_loss: 0.3202 - val_accuracy: 0.9028\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2919 - accuracy: 0.9110 - val_loss: 0.2801 - val_accuracy: 0.9171\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.9156 - val_loss: 0.2955 - val_accuracy: 0.9041\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.9149 - val_loss: 0.2768 - val_accuracy: 0.9213\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2614 - accuracy: 0.9176 - val_loss: 0.2939 - val_accuracy: 0.9095\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2672 - accuracy: 0.9187 - val_loss: 0.2624 - val_accuracy: 0.9246\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26243922114372253, 0.9246231317520142]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.26\n",
      "accuracy: 92.46%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions are probabilities.\n",
    "\n",
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.25\n",
      "Train accuracy: 92.23%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2462518811225891, 0.922290027141571]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.26\n",
      "Test accuracy: 92.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26243922114372253, 0.9246231317520142]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                4050      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,305\n",
      "Trainable params: 4,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Deep Cross-Sectional Neural Network model using Keras with two or more hidden layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 80, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "# we have used Pipe Architecture to build a deep neural network model. \n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=80))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dense(5, activation='softmax'))\n",
    "\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 2s 11ms/step - loss: 0.7773 - accuracy: 0.7337 - val_loss: 0.5080 - val_accuracy: 0.8208\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.8290 - val_loss: 0.4759 - val_accuracy: 0.8317\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.8543 - val_loss: 0.3471 - val_accuracy: 0.9091\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3537 - accuracy: 0.8921 - val_loss: 0.3098 - val_accuracy: 0.9133\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8984 - val_loss: 0.2901 - val_accuracy: 0.9221\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.3095 - accuracy: 0.8975 - val_loss: 0.3003 - val_accuracy: 0.9108\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.9052 - val_loss: 0.2716 - val_accuracy: 0.9167\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2771 - accuracy: 0.9108 - val_loss: 0.2428 - val_accuracy: 0.9250\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.9225 - val_loss: 0.3113 - val_accuracy: 0.8974\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2598 - accuracy: 0.9140 - val_loss: 0.2587 - val_accuracy: 0.9167\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2335 - accuracy: 0.9266 - val_loss: 0.2542 - val_accuracy: 0.9255\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2385 - accuracy: 0.9226 - val_loss: 0.2301 - val_accuracy: 0.9384\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9300 - val_loss: 0.2168 - val_accuracy: 0.9422\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2253 - accuracy: 0.9279 - val_loss: 0.2300 - val_accuracy: 0.9326\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9296 - val_loss: 0.2380 - val_accuracy: 0.9271\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2256 - accuracy: 0.9305 - val_loss: 0.2795 - val_accuracy: 0.9188\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9345 - val_loss: 0.2479 - val_accuracy: 0.9259\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.2069 - accuracy: 0.9347 - val_loss: 0.2099 - val_accuracy: 0.9481\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.9383 - val_loss: 0.2226 - val_accuracy: 0.9397\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1738 - accuracy: 0.9463 - val_loss: 0.2634 - val_accuracy: 0.9313\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(train_x, train_target, \n",
    "                    validation_data=(test_x, test_target), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26339027285575867, 0.9313232898712158]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.26\n",
      "accuracy: 93.13%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.26\n",
      "Test accuracy: 93.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26339027285575867, 0.9313232898712158]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n",
    "test_scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.20\n",
      "Train accuracy: 93.92%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1965837925672531, 0.9391601085662842]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n",
    "train_scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 80)                6480      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 405       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,845\n",
      "Trainable params: 19,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM Model with only one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(80, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=15, verbose=1, mode='max')\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 20s 89ms/step - loss: 1.1302 - accuracy: 0.5732 - val_loss: 1.0728 - val_accuracy: 0.5741\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 15s 87ms/step - loss: 1.0789 - accuracy: 0.5849 - val_loss: 1.0459 - val_accuracy: 0.5787\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 15s 87ms/step - loss: 1.0427 - accuracy: 0.5991 - val_loss: 0.9835 - val_accuracy: 0.6198\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 15s 87ms/step - loss: 0.8442 - accuracy: 0.6974 - val_loss: 0.8447 - val_accuracy: 0.7006\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 0.6247 - accuracy: 0.7968 - val_loss: 0.5772 - val_accuracy: 0.8128\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 15s 85ms/step - loss: 0.5615 - accuracy: 0.8189 - val_loss: 0.5222 - val_accuracy: 0.8300\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 0.5012 - accuracy: 0.8482 - val_loss: 0.4954 - val_accuracy: 0.8446\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 14s 80ms/step - loss: 0.4671 - accuracy: 0.8579 - val_loss: 0.4315 - val_accuracy: 0.8689\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 0.4462 - accuracy: 0.8634 - val_loss: 0.4304 - val_accuracy: 0.8706\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 15s 86ms/step - loss: 0.4223 - accuracy: 0.8661 - val_loss: 0.6197 - val_accuracy: 0.8011\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 14s 81ms/step - loss: 0.4364 - accuracy: 0.8659 - val_loss: 0.3928 - val_accuracy: 0.8798\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 15s 85ms/step - loss: 0.3736 - accuracy: 0.8871 - val_loss: 0.3943 - val_accuracy: 0.8840\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 14s 79ms/step - loss: 0.3579 - accuracy: 0.8938 - val_loss: 0.3236 - val_accuracy: 0.9100\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 15s 84ms/step - loss: 0.3337 - accuracy: 0.9009 - val_loss: 0.3512 - val_accuracy: 0.8957\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.3209 - accuracy: 0.9040 - val_loss: 0.2887 - val_accuracy: 0.9213\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 8s 47ms/step - loss: 0.3105 - accuracy: 0.9054 - val_loss: 0.3027 - val_accuracy: 0.9137\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30266693234443665, 0.9137353301048279]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30\n",
      "accuracy: 91.37%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30\n",
      "Train accuracy: 91.51%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29682058095932007, 0.915111243724823]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n",
    "train_scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30\n",
      "Test accuracy: 91.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30266693234443665, 0.9137353301048279]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n",
    "test_scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 80)                26240     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 405       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,645\n",
      "Trainable params: 26,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model with only two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(80, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(80),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 26s 108ms/step - loss: 1.1446 - accuracy: 0.5695 - val_loss: 1.1168 - val_accuracy: 0.5888\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 17s 100ms/step - loss: 1.1177 - accuracy: 0.5791 - val_loss: 1.0593 - val_accuracy: 0.5812\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 18s 102ms/step - loss: 1.1260 - accuracy: 0.5736 - val_loss: 1.1048 - val_accuracy: 0.5888\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 20s 113ms/step - loss: 1.0664 - accuracy: 0.5820 - val_loss: 1.0538 - val_accuracy: 0.5879\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 20s 114ms/step - loss: 1.0493 - accuracy: 0.6010 - val_loss: 1.0336 - val_accuracy: 0.5846\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 20s 115ms/step - loss: 1.0097 - accuracy: 0.6021 - val_loss: 0.9835 - val_accuracy: 0.6374\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 19s 110ms/step - loss: 0.9781 - accuracy: 0.6247 - val_loss: 0.9771 - val_accuracy: 0.6315\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 19s 110ms/step - loss: 1.0673 - accuracy: 0.6010 - val_loss: 1.2179 - val_accuracy: 0.4527\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 20s 112ms/step - loss: 1.0480 - accuracy: 0.6127 - val_loss: 1.0993 - val_accuracy: 0.5833\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 19s 108ms/step - loss: 0.9610 - accuracy: 0.6454 - val_loss: 0.7759 - val_accuracy: 0.7257\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.9357 - accuracy: 0.6517 - val_loss: 0.8750 - val_accuracy: 0.7052\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 18s 103ms/step - loss: 0.8628 - accuracy: 0.6904 - val_loss: 1.0891 - val_accuracy: 0.6265\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 18s 101ms/step - loss: 0.8996 - accuracy: 0.6777 - val_loss: 0.8940 - val_accuracy: 0.6374\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 18s 103ms/step - loss: 0.9859 - accuracy: 0.6197 - val_loss: 0.8523 - val_accuracy: 0.7039\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 18s 104ms/step - loss: 0.9655 - accuracy: 0.6491 - val_loss: 0.8981 - val_accuracy: 0.6851\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.8596 - accuracy: 0.6994 - val_loss: 0.7540 - val_accuracy: 0.7416\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 18s 105ms/step - loss: 0.8018 - accuracy: 0.7254 - val_loss: 0.7760 - val_accuracy: 0.7345\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 19s 107ms/step - loss: 0.7270 - accuracy: 0.7545 - val_loss: 0.7150 - val_accuracy: 0.7659\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 18s 105ms/step - loss: 0.6725 - accuracy: 0.7751 - val_loss: 0.6748 - val_accuracy: 0.7860\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.6437 - accuracy: 0.7841 - val_loss: 0.6355 - val_accuracy: 0.7881\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6354867815971375, 0.7881072163581848]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.64\n",
      "accuracy: 78.81%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.62\n",
      "Train accuracy: 79.15%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6183532476425171, 0.7914572954177856]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.64\n",
      "Test accuracy: 78.81%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6354867815971375, 0.7881072163581848]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 80, 80)            26240     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 80)                51520     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 405       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,165\n",
      "Trainable params: 78,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model with only one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(80, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 12s 45ms/step - loss: 1.0788 - accuracy: 0.5872 - val_loss: 1.0243 - val_accuracy: 0.6093\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 8s 47ms/step - loss: 0.7713 - accuracy: 0.7195 - val_loss: 0.5232 - val_accuracy: 0.8128\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.4878 - accuracy: 0.8360 - val_loss: 0.4050 - val_accuracy: 0.8693\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.3982 - accuracy: 0.8744 - val_loss: 0.5457 - val_accuracy: 0.8296\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.3804 - accuracy: 0.8796 - val_loss: 0.3687 - val_accuracy: 0.8920\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.3377 - accuracy: 0.8963 - val_loss: 0.3230 - val_accuracy: 0.9049\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 8s 47ms/step - loss: 0.3121 - accuracy: 0.9043 - val_loss: 0.3058 - val_accuracy: 0.9112\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.2921 - accuracy: 0.9099 - val_loss: 0.2595 - val_accuracy: 0.9234\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.2732 - accuracy: 0.9148 - val_loss: 0.3331 - val_accuracy: 0.8920\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 8s 46ms/step - loss: 0.2687 - accuracy: 0.9119 - val_loss: 0.3108 - val_accuracy: 0.8966\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.2568 - accuracy: 0.9174 - val_loss: 0.2733 - val_accuracy: 0.9204\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.2240 - accuracy: 0.9262 - val_loss: 0.2481 - val_accuracy: 0.9305\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.2410 - accuracy: 0.9259 - val_loss: 0.2270 - val_accuracy: 0.9355\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 0.2158 - accuracy: 0.9322 - val_loss: 0.2275 - val_accuracy: 0.9334\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.1849 - accuracy: 0.9427 - val_loss: 0.2208 - val_accuracy: 0.9414\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 8s 48ms/step - loss: 0.1917 - accuracy: 0.9413 - val_loss: 0.2180 - val_accuracy: 0.9414\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21802346408367157, 0.9413735270500183]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.22\n",
      "accuracy: 94.14%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.16\n",
      "Train accuracy: 94.72%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16185347735881805, 0.947236180305481]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n",
    "train_scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.22\n",
      "Test accuracy: 94.14%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21802346408367157, 0.9413735270500183]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 80)                19920     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 5)                 405       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,325\n",
      "Trainable params: 20,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep GRU Model with only two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(80, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(80),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 25s 103ms/step - loss: 0.9350 - accuracy: 0.6502 - val_loss: 0.6522 - val_accuracy: 0.7848\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.4787 - accuracy: 0.8505 - val_loss: 0.3850 - val_accuracy: 0.8853\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.3741 - accuracy: 0.8808 - val_loss: 0.5343 - val_accuracy: 0.8141\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.3249 - accuracy: 0.8975 - val_loss: 0.2726 - val_accuracy: 0.9204\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.2898 - accuracy: 0.9081 - val_loss: 0.6387 - val_accuracy: 0.8237\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 19s 108ms/step - loss: 0.3340 - accuracy: 0.8918 - val_loss: 0.3179 - val_accuracy: 0.9100\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 19s 111ms/step - loss: 0.2892 - accuracy: 0.9104 - val_loss: 0.2957 - val_accuracy: 0.9150\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 18s 101ms/step - loss: 0.3778 - accuracy: 0.8740 - val_loss: 0.3007 - val_accuracy: 0.9108\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 19s 110ms/step - loss: 0.2969 - accuracy: 0.9042 - val_loss: 0.2783 - val_accuracy: 0.9146\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 18s 105ms/step - loss: 0.2778 - accuracy: 0.9142 - val_loss: 0.2645 - val_accuracy: 0.9121\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 19s 110ms/step - loss: 0.2368 - accuracy: 0.9232 - val_loss: 0.2789 - val_accuracy: 0.9188\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 19s 110ms/step - loss: 0.2216 - accuracy: 0.9314 - val_loss: 0.2752 - val_accuracy: 0.9150\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.4377 - accuracy: 0.8595 - val_loss: 0.5988 - val_accuracy: 0.7730\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 19s 109ms/step - loss: 0.6126 - accuracy: 0.8033 - val_loss: 0.5354 - val_accuracy: 0.8078\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 19s 107ms/step - loss: 0.4552 - accuracy: 0.8537 - val_loss: 0.4373 - val_accuracy: 0.8572\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 19s 106ms/step - loss: 0.4075 - accuracy: 0.8668 - val_loss: 0.4351 - val_accuracy: 0.8580\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.435077965259552, 0.8580402135848999]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.44\n",
      "accuracy: 85.80%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.41\n",
      "Train accuracy: 86.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41383096575737, 0.8618090748786926]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train values\n",
    "\n",
    "train_scores = model.evaluate(train_x, train_y, verbose=0)\n",
    "print(f\"Train {model.metrics_names[0]}: {train_scores[0]:.2f}\")\n",
    "print(f\"Train {model.metrics_names[1]}: {train_scores[1]*100:.2f}%\")\n",
    "\n",
    "train_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.44\n",
      "Test accuracy: 85.80%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.435077965259552, 0.8580402135848999]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "\n",
    "test_scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(f\"Test {model.metrics_names[0]}: {test_scores[0]:.2f}\")\n",
    "print(f\"Test {model.metrics_names[1]}: {test_scores[1]*100:.2f}%\")\n",
    "\n",
    "test_scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 80, 80)            19920     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 80)                38880     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 5)                 405       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,205\n",
      "Trainable params: 59,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you buid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Baseline Test Accuracy: 58.87%\n",
    "\n",
    "Cross-Sectional Neural Network model using Keras with only one hidden layer : Test Accuracy: 92.46%\n",
    "\n",
    "Deep Cross-Sectional Neural Network model using Keras with two or more hidden layers : Test Accuracy: 93.13%\n",
    "\n",
    "LSTM Model with only one layer : Test Accuracy: 91.37%\n",
    "\n",
    "Deep LSTM Model with only two layers : Test Accuracy: 78.81%\n",
    "\n",
    "GRU Model with only one layer : Test Accuracy: 94.14%\n",
    "\n",
    "Deep GRU Model with only two layers : Test Accuracy: 85.80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The GRU model with one layer has the highest accuracy of 94.14%. \n",
    "\n",
    "It outperforms all other models and When Compared to the other models listed, the GRU model with only one layer achieved the highest test accuracy, indicating that it was able to learn the patterns in the data more effectively. \n",
    "\n",
    "The Deep Cross-Sectional Neural Network model using Keras with two or more hidden layers also achieved a high test accuracy(93.13%), but it has more parameters and may be more prone to overfitting. And, the GRU is a type of recurrent neural network that is similar to the LSTM  but has fewer parameters and is faster to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it compare to baseline?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The best model in this case is the GRU model with only one layer, which achieved a test accuracy of 94.14%. \n",
    "\n",
    "In comparison, the baseline test accuracy was 58.87%. This means that the GRU model outperformed our baseline by a large margin, improving the test accuracy by about 34%. The GRU model was able to capture more complex patterns in the data easily. \n",
    "\n",
    "Additionally, the use of a single GRU layer with the appropriate number of units may have allowed the model to learn the relevant patterns in the data without overfitting, resulting in better generalization performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
